{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk4lxknXUbWl"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pymystem3\n",
        "from pymystem3 import Mystem\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUNkJYceUgAm",
        "outputId": "258b21a3-3d26-490f-d2bd-5d1847ecfdf9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDXFSqYbUh67"
      },
      "outputs": [],
      "source": [
        "folder = \"/4  курс/Информационный поиск/task1\" \n",
        "writeFolder = \"/4  курс/Информационный поиск/task2\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IzHFV4HUouZ",
        "outputId": "30340037-42e7-4091-dd7f-cab8aef6e334"
      },
      "outputs": [],
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt') # без этого не работает word_tokenize\n",
        "stop_ru = stopwords.words('russian') # союзы и тд\n",
        "stop_en = stopwords.words('english')\n",
        "m = Mystem()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNOo3KrIUryZ"
      },
      "outputs": [],
      "source": [
        "# регулярка для вычищения слов с цифрами или символами внутри (моне*та, например)\n",
        "# не ищет слова, оканчивающиеся символом или цифрой (чтобы оставить все слова с точками и запятыми)\n",
        "CLEANR = re.compile('[a-zA-Zа-яА-Я]*[^a-zA-Zа-яА-Я\\s]+[a-zA-Zа-яА-Я]+')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmGvkYKMVD5P",
        "outputId": "8890b8ee-a35f-4754-df15-f13f141384c3"
      },
      "outputs": [],
      "source": [
        "tokens = []\n",
        "lemmas = {}\n",
        "\n",
        "for dirpath, _, filenames in os.walk('/content/drive/My Drive/'+ folder):\n",
        "  for filename in filenames:\n",
        "    \n",
        "    with open('/content/drive/My Drive/'+ folder +'/' + filename, 'rb') as f:\n",
        "        data = f.read()\n",
        "        print(filename)\n",
        "        # очищает html тэги\n",
        "        soup = BeautifulSoup(data, 'html.parser')\n",
        "        for data in soup(['style', 'script']):\n",
        "            # Remove tags\n",
        "            data.decompose()\n",
        "    \n",
        "        # return data by retrieving the tag content\n",
        "        answer = ' '.join(soup.stripped_strings)\n",
        "      \n",
        "        clean_answer = re.sub(CLEANR, ' ', answer)\n",
        "        # убираем все цифры\n",
        "        clean_answer = re.sub(r\"\\d+\", \" \", clean_answer)\n",
        "        # удаляем знаки препинания\n",
        "        clean_answer = re.sub(r'[^\\w\\s]', '', clean_answer)\n",
        "        # выделяет токены - слова\n",
        "        words = word_tokenize(clean_answer, language=\"russian\")\n",
        "\n",
        "        for word in words:\n",
        "            word = word.lower()\n",
        "            if word not in stop_ru and word not in stop_en:\n",
        "                if word not in tokens:\n",
        "                    tokens.append(word)\n",
        "                lemma = m.lemmatize(word)[0]\n",
        "                if lemma not in lemmas.keys():\n",
        "                    lemmas[lemma] = set()\n",
        "                lemmas[lemma].add(word)    \n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMN4d5CkMR4z"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/My Drive/' + writeFolder + '/tokens.txt', 'w') as f:\n",
        "  for token in tokens:\n",
        "        f.write(f\"{token}\\n\")       \n",
        "\n",
        "with open('/content/drive/My Drive/' + writeFolder + '/lemmas.txt', 'w') as f:\n",
        "  for lemma in lemmas.keys():\n",
        "        f.write(f\"{lemma}: \")  \n",
        "        for token in lemmas[lemma]:\n",
        "          f.write(f\"{token} \")\n",
        "        f.write(f\"\\n\")       "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
